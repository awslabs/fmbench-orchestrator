# general configuration applicable to the entire app
general:
  name: llama3.2-1b-cpu

# Take the below as list of dict as there might be 2 instances with the same AMI
defaults: &cpu_settings
  region: {{region}}
  ami_id: {{cpu}}
  device_name: /dev/xvda
  ebs_del_on_termination: True
  ebs_Iops: 16000
  ebs_VolumeSize: 250
  ebs_VolumeType: gp3
  startup_script: startup_scripts/cpu_al2023_startup.txt
  post_startup_script: post_startup_scripts/fmbench.txt
  # Timeout period in Seconds before a run is stopped
  fmbench_complete_timeout: 3600

instances:

- instance_type: m7a.24xlarge
  <<: *cpu_settings  
  fmbench_config: 
  - fmbench:llama3.2/1b/config-llama3.2-1b-m7a-24xlarge-ec2-summarization.yml
  upload_files:
  - local: byo_dataset/synthetic_data_large_prompts.jsonl
    remote: /tmp/fmbench-read/source_data/
  - local: byo_dataset/prompt_template_llama3_summarization.txt
    remote: /tmp/fmbench-read/prompt_template/
